{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"HDLLDL_srWGS_dataset\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_55136786_person_sql <- paste(\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `person` person \n",
    "    LEFT JOIN\n",
    "        `concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `cb_search_person` p \n",
    "            WHERE\n",
    "                has_whole_genome_variant = 1 ) \n",
    "            AND cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (40782589, 40795800)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "person_55136786_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"person_55136786\",\n",
    "  \"person_55136786_*.csv\")\n",
    "message(str_glue('The data will be written to {person_55136786_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_55136786_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  person_55136786_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {person_55136786_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_55136786_person_df <- read_bq_export_from_workspace_bucket(person_55136786_path)\n",
    "\n",
    "dim(dataset_55136786_person_df)\n",
    "\n",
    "head(dataset_55136786_person_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(dataset_55136786_person_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(duplicated(dataset_55136786_person_df$person_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_55136786_person_df$sexM = NA\n",
    "dataset_55136786_person_df$sexM[dataset_55136786_person_df$sex_at_birth == \"Female\"] = 0\n",
    "dataset_55136786_person_df$sexM[dataset_55136786_person_df$sex_at_birth == \"Male\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.table(\n",
    "    dataset_55136786_person_df[, c(\"person_id\", \"sexM\", \"date_of_birth\")],\n",
    "    sep = \"\\t\",\n",
    "    na = \"NA\",\n",
    "    row.names = FALSE,\n",
    "    quote = FALSE,\n",
    "    file = \"HDLLDL_srWGS_person.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(bigrquery)\n",
    "\n",
    "# This query represents dataset \"HDLLDL_srWGS_dataset\" for domain \"measurement\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_55136786_measurement_sql <- paste(\"\n",
    "    SELECT\n",
    "        measurement.person_id,\n",
    "        measurement.measurement_concept_id,\n",
    "        m_standard_concept.concept_name as standard_concept_name,\n",
    "        m_standard_concept.concept_code as standard_concept_code,\n",
    "        m_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        measurement.measurement_datetime,\n",
    "        measurement.measurement_type_concept_id,\n",
    "        m_type.concept_name as measurement_type_concept_name,\n",
    "        measurement.operator_concept_id,\n",
    "        m_operator.concept_name as operator_concept_name,\n",
    "        measurement.value_as_number,\n",
    "        measurement.value_as_concept_id,\n",
    "        m_value.concept_name as value_as_concept_name,\n",
    "        measurement.unit_concept_id,\n",
    "        m_unit.concept_name as unit_concept_name,\n",
    "        measurement.range_low,\n",
    "        measurement.range_high,\n",
    "        measurement.visit_occurrence_id,\n",
    "        m_visit.concept_name as visit_occurrence_concept_name,\n",
    "        measurement.measurement_source_value,\n",
    "        measurement.measurement_source_concept_id,\n",
    "        m_source_concept.concept_name as source_concept_name,\n",
    "        m_source_concept.concept_code as source_concept_code,\n",
    "        m_source_concept.vocabulary_id as source_vocabulary,\n",
    "        measurement.unit_source_value,\n",
    "        measurement.value_source_value \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `measurement` measurement \n",
    "        WHERE\n",
    "            (\n",
    "                measurement_concept_id IN (SELECT\n",
    "                    DISTINCT c.concept_id \n",
    "                FROM\n",
    "                    `cb_criteria` c \n",
    "                JOIN\n",
    "                    (SELECT\n",
    "                        CAST(cr.id as string) AS id       \n",
    "                    FROM\n",
    "                        `cb_criteria` cr       \n",
    "                    WHERE\n",
    "                        concept_id IN (3038553, 40782589, 40795800)       \n",
    "                        AND full_text LIKE '%_rank1]%'      ) a \n",
    "                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                        OR c.path LIKE CONCAT('%.', a.id) \n",
    "                        OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                        OR c.path = a.id) \n",
    "                WHERE\n",
    "                    is_standard = 1 \n",
    "                    AND is_selectable = 1)\n",
    "            )  \n",
    "            AND (\n",
    "                measurement.PERSON_ID IN (SELECT\n",
    "                    distinct person_id  \n",
    "                FROM\n",
    "                    `cb_search_person` cb_search_person  \n",
    "                WHERE\n",
    "                    cb_search_person.person_id IN (SELECT\n",
    "                        person_id \n",
    "                    FROM\n",
    "                        `cb_search_person` p \n",
    "                    WHERE\n",
    "                        has_whole_genome_variant = 1 ) \n",
    "                    AND cb_search_person.person_id IN (SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id, entry_date, concept_id \n",
    "                        FROM\n",
    "                            `cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (concept_id IN(SELECT\n",
    "                                DISTINCT c.concept_id \n",
    "                            FROM\n",
    "                                `cb_criteria` c \n",
    "                            JOIN\n",
    "                                (SELECT\n",
    "                                    CAST(cr.id as string) AS id       \n",
    "                                FROM\n",
    "                                    `cb_criteria` cr       \n",
    "                                WHERE\n",
    "                                    concept_id IN (40782589, 40795800)       \n",
    "                                    AND full_text LIKE '%_rank1]%'      ) a \n",
    "                                    ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                                    OR c.path LIKE CONCAT('%.', a.id) \n",
    "                                    OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                                    OR c.path = a.id) \n",
    "                            WHERE\n",
    "                                is_standard = 1 \n",
    "                                AND is_selectable = 1) \n",
    "                            AND is_standard = 1 )) criteria ) )\n",
    "            )) measurement \n",
    "    LEFT JOIN\n",
    "        `concept` m_standard_concept \n",
    "            ON measurement.measurement_concept_id = m_standard_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_type \n",
    "            ON measurement.measurement_type_concept_id = m_type.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_operator \n",
    "            ON measurement.operator_concept_id = m_operator.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_value \n",
    "            ON measurement.value_as_concept_id = m_value.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_unit \n",
    "            ON measurement.unit_concept_id = m_unit.concept_id \n",
    "    LEFT JOIn\n",
    "        `visit_occurrence` v \n",
    "            ON measurement.visit_occurrence_id = v.visit_occurrence_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_visit \n",
    "            ON v.visit_concept_id = m_visit.concept_id \n",
    "    LEFT JOIN\n",
    "        `concept` m_source_concept \n",
    "            ON measurement.measurement_source_concept_id = m_source_concept.concept_id\", sep=\"\")\n",
    "\n",
    "# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n",
    "# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n",
    "#       But data exported on a different days will write to a new location so that historical\n",
    "#       copies can be kept as the dataset definition is changed.\n",
    "measurement_55136786_path <- file.path(\n",
    "  Sys.getenv(\"WORKSPACE_BUCKET\"),\n",
    "  \"bq_exports\",\n",
    "  Sys.getenv(\"OWNER_EMAIL\"),\n",
    "  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n",
    "  \"measurement_55136786\",\n",
    "  \"measurement_55136786_*.csv\")\n",
    "message(str_glue('The data will be written to {measurement_55136786_path}. Use this path when reading ',\n",
    "                 'the data into your notebooks in the future.'))\n",
    "\n",
    "# Perform the query and export the dataset to Cloud Storage as CSV files.\n",
    "# NOTE: You only need to run `bq_table_save` once. After that, you can\n",
    "#       just read data from the CSVs in Cloud Storage.\n",
    "bq_table_save(\n",
    "  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_55136786_measurement_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n",
    "  measurement_55136786_path,\n",
    "  destination_format = \"CSV\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data directly from Cloud Storage into memory.\n",
    "# NOTE: Alternatively you can `gsutil -m cp {measurement_55136786_path}` to copy these files\n",
    "#       to the Jupyter disk.\n",
    "read_bq_export_from_workspace_bucket <- function(export_path) {\n",
    "  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character(), measurement_type_concept_name = col_character(), operator_concept_name = col_character(), value_as_concept_name = col_character(), unit_concept_name = col_character(), visit_occurrence_concept_name = col_character(), measurement_source_value = col_character(), source_concept_name = col_character(), source_concept_code = col_character(), source_vocabulary = col_character(), unit_source_value = col_character(), value_source_value = col_character())\n",
    "  bind_rows(\n",
    "    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n",
    "        function(csv) {\n",
    "          message(str_glue('Loading {csv}.'))\n",
    "          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n",
    "          if (is.null(col_types)) {\n",
    "            col_types <- spec(chunk)\n",
    "          }\n",
    "          chunk\n",
    "        }))\n",
    "}\n",
    "dataset_55136786_measurement_df <- read_bq_export_from_workspace_bucket(measurement_55136786_path)\n",
    "\n",
    "dim(dataset_55136786_measurement_df)\n",
    "\n",
    "head(dataset_55136786_measurement_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(table(dataset_55136786_measurement_df$standard_concept_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = dataset_55136786_measurement_df %>%\n",
    "filter(standard_concept_name %in%\n",
    "       c(\"Cholesterol in LDL [Mass/volume] in Serum or Plasma by calculation\",\n",
    "         \"Cholesterol in LDL [Mass/volume] in Serum or Plasma\",\n",
    "         \"Cholesterol in LDL [Mass/volume] in Serum or Plasma by Direct assay\",\n",
    "         \"Cholesterol in LDL [Mass/volume] in Serum or Plasma ultracentrifugate\",\n",
    "         \"Cholesterol in LDL [Mass/volume] in Serum or Plasma by Electrophoresis\")) %>%\n",
    "#filter(unit_concept_name %in%\n",
    "#      c(\"milligram per deciliter\", \"No matching concept\", \"milligram per deciliter calculated\", \"milligram per milliliter\", \"mg/dL\"))\n",
    "select(person_id, measurement_datetime, value_as_number) %>%\n",
    "na.omit() %>%\n",
    "mutate(measurement_datetime = as.Date(measurement_datetime)) %>%\n",
    "filter(value_as_number > 0) %>%\n",
    "filter(value_as_number < 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = quantile(obs$value_as_number, seq(0.001, 0.999, 0.001))\n",
    "plot(x)\n",
    "obs$value_as_number[(obs$value_as_number < min(x) | obs$value_as_number > max(x))] = NA\n",
    "\n",
    "obs = obs[!is.na(obs$value_as_number), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.table(obs, \"HDLLDL_srWGS.LDL.txt\", row.names=FALSE, quote=FALSE, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDL190 = unique(x$person_id)\n",
    "length(LDL190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset_55136786_measurement_df %>%\n",
    "filter(standard_concept_name %in%\n",
    "       c(\"Cholesterol in HDL [Mass/volume] in Serum or Plasma\")) %>%\n",
    "filter(unit_concept_name %in%\n",
    "      c(\"milligram per deciliter\")) %>%\n",
    "select(person_id, value_as_number) %>%\n",
    "na.omit() %>%\n",
    "filter(value_as_number > 0) %>%\n",
    "filter(value_as_number < 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(x$value_as_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDL40 = unique(x$person_id)\n",
    "length(HDL40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be too many HDL40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = read.table(\"lipidaemia_srWGS_withC10B_person.txt\", header=TRUE, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(LDL190 %in% foo$person_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of LDL190 are already captured in lipidaemia_srWGS_withC10B_person.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output =\n",
    "dataset_55136786_measurement_df %>%\n",
    "    filter(standard_concept_name == \"Body mass index (BMI) [Ratio]\") %>%\n",
    "    select(person_id, value_as_number) %>%\n",
    "    na.omit() %>%\n",
    "    mutate(lower = quantile(value_as_number, 0.01),\n",
    "           upper = quantile(value_as_number, 0.99)) %>%\n",
    "    filter(value_as_number >= lower & value_as_number <= upper) %>%\n",
    "    group_by(person_id) %>%\n",
    "    summarize(BMI = median(value_as_number))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.table(\n",
    "    output,\n",
    "    sep = \"\\t\",\n",
    "    na = \"NA\",\n",
    "    row.names = FALSE,\n",
    "    quote = FALSE,\n",
    "    file = \"HDLLDL_srWGS_BMI.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"metadata": {"language_info": {"name": "python", "version": "3.12.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3 (ipykernel)", "language": "python"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "drug = 'thiazide'\n#drug = 'b-blocker'\n#drug = 'ACEi'\n#drug = 'ARB'\n#drug = 'CCB'\n#drug = 'ezetimibe'\n#drug = 'fibrate'\n#drug = 'statin'\n#drug = 'insulin'\n#drug = 'biguanide'\n#drug = 'sulfonylurea'\n#drug = 'thiazolidinedione'\n#drug = 'antidiabetic_drugs_excl_biguanide_sulfonylurea'\n#drug = 'bileacidsequestrant'\n#drug = 'nicotinicacid'\n#drug = 'omega3'\nfile_bnf    = f'bnf_{drug}.txt'\nfile_read_2 = f'read_2_{drug}.txt'\nfile_dmd    = f'dmd_{drug}.txt'\nfile_out    = f'{drug}.txt'\n\nfile_drug_name = f'drug_name_{drug}.txt' #thiazolidinedione", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "import subprocess\noutput = subprocess.check_output(['wc', '-l', file_bnf, file_read_2, file_dmd])\nprint(output.decode('utf-8'))  # Decode bytes to string", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "import pyspark\nimport dxpy\nimport dxdata\nsc = pyspark.SparkContext()\nspark = pyspark.sql.SparkSession(sc)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "import pandas as pd\nimport os", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "dispensed_database_name = dxpy.find_one_data_object(classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True)[\"describe\"][\"name\"]\ndispensed_dataset_id = dxpy.find_one_data_object(typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\")[\"id\"]", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "spark.sql(\"USE \" + dispensed_database_name)\nspark.sql(\"SHOW TABLES\").show(truncate=False)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "spark.sql(\"SELECT * FROM gp_scripts LIMIT 5\").toPandas()", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "result = spark.sql(\"SELECT * FROM gp_scripts LIMIT 0\").toPandas()\nresult", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "foo = pd.read_csv(file_bnf, sep='\\t', header=None, dtype=object)\nfoo.shape[0]", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for k in foo.iloc[:,0]:\n    k = k.rstrip()\n    q = f\"SELECT * FROM gp_scripts WHERE bnf_code LIKE '{k}' || '%'\"\n    df = spark.sql(q).toPandas()\n    c = df.shape[0]\n    print(q + f\" ==> {c}\")\n    if c > 0:\n        result = pd.concat([result, df])", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "print(result.shape[0])\nresult = result.drop_duplicates()\nprint(result.shape[0])", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "foo = pd.read_csv(file_read_2, sep='\\t', header=None, dtype=object)\nfoo.shape[0]", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for k in foo.iloc[:,0]:\n    k = k.rstrip()\n    q = f\"SELECT * FROM gp_scripts WHERE read_2 LIKE '{k}' || '%'\"\n    df = spark.sql(q).toPandas()\n    c = df.shape[0]\n    print(q + f\" ==> {c}\")\n    if c > 0:\n        result = pd.concat([result, df])", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "print(result.shape[0])\nresult = result.drop_duplicates()\nprint(result.shape[0])", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "foo = pd.read_csv(file_dmd, sep='\\t', header=None, dtype=object)\nfoo.shape[0]", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for k in foo.iloc[:,0]:\n    k = k.rstrip()\n    q = f\"SELECT * FROM gp_scripts WHERE dmd_code = '{k}'\"\n    df = spark.sql(q).toPandas()\n    c = df.shape[0]\n    print(q + f\" ==> {c}\")\n    if c > 0:\n        result = pd.concat([result, df])", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "print(result.shape[0])\nresult = result.drop_duplicates()\nprint(result.shape[0])", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "raw", "source": "foo = pd.read_csv(file_drug_name, sep='\\t', header=None, dtype=object)\nfoo.shape[0]", "metadata": {"tags": []}}, {"cell_type": "raw", "source": "for k in foo.iloc[:,0]:\n    k = k.rstrip()\n    q = f\"SELECT * FROM gp_scripts WHERE drug_name LIKE '%' || '{k}' || '%'\"\n    df = spark.sql(q).toPandas()\n    c = df.shape[0]\n    print(q + f\" ==> {c}\")\n    if c > 0:\n        result = pd.concat([result, df])", "metadata": {"tags": []}}, {"cell_type": "raw", "source": "print(result.shape[0])\nresult = result.drop_duplicates()\nprint(result.shape[0])", "metadata": {}}, {"cell_type": "code", "source": "all_columns = result.columns.to_list()\nresult.sort_values(by=all_columns, inplace=True)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "result.head(5)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "result.to_csv(file_out, sep='\\t', index=False)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "os.system(f'dx upload {file_out}')", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Extract earliest issue_date for each eid", "metadata": {}}, {"cell_type": "markdown", "source": "- where clinical event or prescription date precedes participant date of birth it has been altered to 01/01/1901.\n- Where the date matches participant date of birth it has been altered to 02/02/1902.\n- Where the date follows participant date of birth but is in the year of their birth it has been altered to 03/03/1903.\n- Where the date was in the future this has been changed to 07/07/2037 as these are likely to have been entered as a place-holder or other system default.", "metadata": {}}, {"cell_type": "code", "source": "result_df = spark.sql(\"\"\"\n    SELECT eid, MIN(issue_date) as earliest_issue_date\n    FROM gp_scripts\n    WHERE issue_date NOT IN ('1901-01-01', '1902-02-02', '1903-03-03', '2037-07-07')\n    GROUP BY eid\n\"\"\")", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "result_pd = result_df.toPandas()", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "result_pd", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "result_pd.to_csv(\"earliest_issue_date.txt\", sep=\"\\t\", index=False)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}]}